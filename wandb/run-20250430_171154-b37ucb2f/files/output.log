wandb 运行已初始化:
  实体: electrixoul-tsinghua-university
  项目: mnist-sae-training
  运行名称: mnist-sae-train-k50
  运行 URL: https://wandb.ai/electrixoul-tsinghua-university/mnist-sae-training/runs/b37ucb2f
加载MNIST数据集...
MNIST训练集: 60000 样本
MNIST测试集: 10000 样本
模型结构:
SparseAutoencoder(
  (encoders): ModuleList(
    (0-4): 5 x Linear(in_features=784, out_features=1024, bias=True)
  )
)
初始模型保存到: mnist_sae_models/mnist_sae_initial.pth
开始训练SAE模型...
轮次 1/5
self.device:  cuda
consensus_loss:  tensor(2.2054e-06, device='cuda:0', dtype=torch.float16,
       grad_fn=<MulBackward0>)
consensus_loss:  tensor(8.7619e-06, device='cuda:0', dtype=torch.float16,
       grad_fn=<MulBackward0>)
/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scalers = [torch.cuda.amp.GradScaler() for _ in self.base_model.encoders]
/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py:92: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
consensus_loss:  tensor(1.9729e-05, device='cuda:0', dtype=torch.float16,
       grad_fn=<MulBackward0>)
consensus_loss:  tensor(3.4988e-05, device='cuda:0', dtype=torch.float16,
       grad_fn=<MulBackward0>)
consensus_loss:  tensor(5.4657e-05, device='cuda:0', dtype=torch.float16,
       grad_fn=<MulBackward0>)
consensus_loss:  tensor(7.8499e-05, device='cuda:0', dtype=torch.float16,
       grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0001, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0001, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0002, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0003, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0004, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0004, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0005, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0005, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0006, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0007, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0008, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0008, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0009, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0010, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0011, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0012, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0013, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0013, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0014, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0015, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0016, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0017, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0018, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0019, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0020, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0022, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0023, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0024, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0025, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0026, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0073, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0072, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0071, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0070, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0069, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0068, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0067, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0066, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0065, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0064, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0063, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0062, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0061, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0060, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0059, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0058, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0057, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0056, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0055, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0054, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
模型保存到: mnist_sae_models/mnist_sae_epoch_1.pth
模型保存到: mnist_sae_models/mnist_sae_epoch_1.pth
开始测试重构效果 (使用SAE 0)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9435
开始测试重构效果 (使用SAE 1)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9441
开始测试重构效果 (使用SAE 2)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9439
开始测试重构效果 (使用SAE 3)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9445
开始测试重构效果 (使用SAE 4)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9442
轮次 2/5
self.device:  cuda
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0053, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0052, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0051, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0050, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0049, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0048, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0047, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0046, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0045, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0044, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0043, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0042, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0041, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
模型保存到: mnist_sae_models/mnist_sae_epoch_1.pth
模型保存到: mnist_sae_models/mnist_sae_epoch_2.pth
开始测试重构效果 (使用SAE 0)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9582
开始测试重构效果 (使用SAE 1)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9591
开始测试重构效果 (使用SAE 2)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9585
开始测试重构效果 (使用SAE 3)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9587
开始测试重构效果 (使用SAE 4)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9592
轮次 3/5
self.device:  cuda
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0040, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0039, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0038, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0037, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0036, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0035, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0034, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
模型保存到: mnist_sae_models/mnist_sae_epoch_1.pth
模型保存到: mnist_sae_models/mnist_sae_epoch_3.pth
开始测试重构效果 (使用SAE 0)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9651
开始测试重构效果 (使用SAE 1)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9656
开始测试重构效果 (使用SAE 2)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9653
开始测试重构效果 (使用SAE 3)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9650
开始测试重构效果 (使用SAE 4)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9659
轮次 4/5
self.device:  cuda
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0033, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0032, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0031, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0030, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
模型保存到: mnist_sae_models/mnist_sae_epoch_1.pth
模型保存到: mnist_sae_models/mnist_sae_epoch_4.pth
开始测试重构效果 (使用SAE 0)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9686
开始测试重构效果 (使用SAE 1)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9687
开始测试重构效果 (使用SAE 2)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9687
开始测试重构效果 (使用SAE 3)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9685
开始测试重构效果 (使用SAE 4)...
已处理 64 个样本 (批次 0/50)
已处理 704 个样本 (批次 10/50)
已处理 1344 个样本 (批次 20/50)
已处理 1984 个样本 (批次 30/50)
已处理 2624 个样本 (批次 40/50)
已处理 3264 个样本 (批次 50/50)
测试完成。平均相关系数: 0.9691
轮次 5/5
self.device:  cuda
consensus_loss:  tensor(0.0029, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0028, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
Traceback (most recent call last):
  File "/home/t/workspace/lab_work/sae_demo/mnist_sae_train.py", line 390, in <module>
    main()
  File "/home/t/workspace/lab_work/sae_demo/mnist_sae_train.py", line 329, in main
    trainer.train(train_loader, 1)
  File "/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py", line 96, in train
    consensus_loss = self.calculate_consensus_loss(encoder_weights)
  File "/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py", line 54, in calculate_consensus_loss
    mmcs_values = [1 - calculate_MMCS(a.clone(), b.clone(), self.device)[0] for a, b in pairs]
  File "/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py", line 54, in <listcomp>
    mmcs_values = [1 - calculate_MMCS(a.clone(), b.clone(), self.device)[0] for a, b in pairs]
  File "/home/t/workspace/lab_work/sae_demo/utils/general_utils.py", line 34, in calculate_MMCS
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/t/workspace/lab_work/sae_demo/mnist_sae_train.py", line 390, in <module>
    main()
  File "/home/t/workspace/lab_work/sae_demo/mnist_sae_train.py", line 329, in main
    trainer.train(train_loader, 1)
  File "/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py", line 96, in train
    consensus_loss = self.calculate_consensus_loss(encoder_weights)
  File "/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py", line 54, in calculate_consensus_loss
    mmcs_values = [1 - calculate_MMCS(a.clone(), b.clone(), self.device)[0] for a, b in pairs]
  File "/home/t/workspace/lab_work/sae_demo/custom_sae_trainer.py", line 54, in <listcomp>
    mmcs_values = [1 - calculate_MMCS(a.clone(), b.clone(), self.device)[0] for a, b in pairs]
  File "/home/t/workspace/lab_work/sae_demo/utils/general_utils.py", line 34, in calculate_MMCS
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
KeyboardInterrupt
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)
consensus_loss:  tensor(0.0027, device='cuda:0', dtype=torch.float16, grad_fn=<MulBackward0>)